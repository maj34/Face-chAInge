{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from detector import AgeGenderEstimator\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,txt_path,transform=None,flip=False):\n",
    "        self.imgs_path = []\n",
    "        self.words = []\n",
    "        self.transform = transform\n",
    "        self.flip = flip\n",
    "        self.batch_count = 0\n",
    "        self.img_size = 112\n",
    "            \n",
    "        f = open(txt_path,'r')\n",
    "        lines = f.readlines()\n",
    "        isFirst = True\n",
    "        labels = []\n",
    "        for line in lines:\n",
    "            line = line.rstrip() \n",
    "            if line.startswith('#'):\n",
    "                if isFirst is True:\n",
    "                    isFirst = False\n",
    "                else:\n",
    "                    labels_copy = labels.copy()\n",
    "                    self.words.append(labels_copy)        \n",
    "                    labels.clear()       \n",
    "                path = line[2:]\n",
    "                path = txt_path.replace('label.txt','images/') + path\n",
    "                self.imgs_path.append(path)            \n",
    "            else:\n",
    "                line = line.split(' ')\n",
    "                label = [float(x) for x in line]\n",
    "                labels.append(label)\n",
    "\n",
    "        self.words.append(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_path)    \n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        img = io.imread(self.imgs_path[index])\n",
    "        #img = img.astype(np.float32)/255.0\n",
    "\n",
    "        labels = self.words[index]\n",
    "        annotations = np.zeros((0, 4))\n",
    "        if len(labels) == 0:\n",
    "            return annotations\n",
    "        for idx, label in enumerate(labels):\n",
    "            annotation = np.zeros((1,4))\n",
    "            # bbox\n",
    "            annotation[0,0] = label[0]                  # x1\n",
    "            annotation[0,1] = label[1]                  # y1\n",
    "            annotation[0,2] = label[0] + label[2]       # x2\n",
    "            annotation[0,3] = label[1] + label[3]       # y2\n",
    "\n",
    "            annotations = np.append(annotations,annotation,axis=0)\n",
    "        \n",
    "        sample = {'img':img, 'annot':annotations}\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TrainDataset(\"../data/widerface/train/label.txt\")\n",
    "model = AgeGenderEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/widerface/train/label.txt\", 'r')\n",
    "lines = f.readlines()\n",
    "isFirst = True\n",
    "labels = []\n",
    "for line in lines:\n",
    "    line = line.rstrip() \n",
    "    labels.append(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(ds))):\n",
    "    data = ds[i]\n",
    "    img, annot = data['img'], data['annot']\n",
    "    for j in range(len(annot)):\n",
    "        try:\n",
    "            new_annot = annot[j]\n",
    "            new_annot = [int(i) for i in new_annot]\n",
    "            new_img = img[new_annot[1] : new_annot[3], new_annot[0] : new_annot[2]]\n",
    "            new_img = cv2.resize(new_img, (112, 112))\n",
    "            #####\n",
    "            \n",
    "            output = model.detect(torch.tensor(new_img).unsqueeze(0))\n",
    "            result_list.append([output[0][0], output[1][0]])\n",
    "        except:\n",
    "            result_list.append([\"UNK\", 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i].startswith(\"#\"):\n",
    "        continue\n",
    "    else:\n",
    "        labels[i] = labels[i] + \" \" + result_list[idx][0] + \" \" + result_list[idx][1]\n",
    "        idx += 1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
